{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "2020-02-정보보호와시스템보안-AI악성코드탐지프로젝트.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_0Fr7slTPCb"
      },
      "source": [
        "## 정보보호와 시스템보안\n",
        "### AI악성코드탐지 프로젝트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0B6HZCaTcJv"
      },
      "source": [
        "### 모두Sun\n",
        "20152857 정준권   \n",
        "20152791 강길웅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVpM3mU1TqlY"
      },
      "source": [
        "### 구글드라이브 연동 및 데이터 압축해제 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPsMyK55jexJ",
        "outputId": "c0c701c0-e35a-42d0-e493-5282c466e2c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaTPjHioj9fg"
      },
      "source": [
        "!unzip /content/drive/MyDrive/데이터.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amZ-DrX-T68S"
      },
      "source": [
        "### 사용 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crbCQLuJlG7V"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pprint\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "import glob"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-HNUv9CUA9V"
      },
      "source": [
        "### .csv 작성 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MwrhF6yOQ3h"
      },
      "source": [
        "def write_label_csv(path, result) :\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        wr = csv.writer(f)\n",
        "        wr.writerow(['file', 'predict'])\n",
        "\n",
        "        for i in result :\n",
        "            wr.writerow(i)\n",
        "        \n",
        "        f.close()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc8m-KLAUFQ1"
      },
      "source": [
        "### 인공지능 관련 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEMpK_dzlNQ6"
      },
      "source": [
        "SEED = 41\n",
        "\n",
        "def read_label_csv(path):\n",
        "    label_table = dict()\n",
        "    with open(path, \"r\",encoding=\"cp949\") as f:\n",
        "        for line in f.readlines()[1:]:\n",
        "            fname, label = line.strip().split(\",\")\n",
        "            label_table[fname] = int(label)\n",
        "    return label_table\n",
        "\n",
        "def read_json(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def load_model(**kwargs):\n",
        "    if kwargs[\"model\"] == \"rf\":\n",
        "        return RandomForestClassifier(random_state=kwargs[\"random_state\"], n_jobs=4)\n",
        "    elif kwargs[\"model\"] == \"dt\":\n",
        "        return DecisionTreeClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lgb\":\n",
        "        return LGBMClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"svm\":\n",
        "        return SVC(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lr\":\n",
        "        return LogisticRegression(random_state=kwargs[\"random_state\"], n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"knn\":\n",
        "        return KNeighborsClassifier(n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"adaboost\":\n",
        "        return AdaBoostClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"mlp\":\n",
        "        return MLPClassifier(random_state=kwargs[\"random_state\"])\n",
        "    else:\n",
        "        print(\"Unsupported Algorithm\")\n",
        "        return None\n",
        "    \n",
        "\n",
        "def train(X_train, y_train, model):\n",
        "    '''\n",
        "        머신러닝 모델을 선택하여 학습을 진행하는 함수\n",
        "\t\n",
        "        :param X_train: 학습할 2차원 리스트 특징벡터\n",
        "        :param y_train: 학습할 1차원 리스트 레이블 벡터\n",
        "        :param model: 문자열, 선택할 머신러닝 알고리즘\n",
        "        :return: 학습된 머신러닝 모델 객체\n",
        "    '''\n",
        "    clf = load_model(model=model, random_state=SEED)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def evaluate(X_test, y_test, model):\n",
        "    '''\n",
        "        학습된 머신러닝 모델로 검증 데이터를 검증하는 함수\n",
        "\t\n",
        "        :param X_test: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y_test: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param model: 학습된 머신러닝 모델 객체\n",
        "    '''\n",
        "    predict = model.predict(X_test)\n",
        "    print(\"정확도\", model.score(X_test, y_test))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSEVWxqCUMiS"
      },
      "source": [
        "### test 데이터 예측 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxAoSODhOWfX"
      },
      "source": [
        "def get_test_predict(X_test, model) :\n",
        "    y_predict = model.predict(X_test)\n",
        "    return y_predict"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oWfwAr5UW0I"
      },
      "source": [
        "### 학습 및 검증 파일 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXi0p86JlPSl"
      },
      "source": [
        "label_table = read_label_csv(\"/content/학습데이터_정답.csv\")\n",
        "label_test_table = read_label_csv(\"/content/검증데이터_정답.csv\")\n",
        "\n",
        "file_list = glob.glob('/content/EMBER/학습데이터/*.json')\n",
        "file_test_list = glob.glob('/content/EMBER/검증데이터/*.json')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3pyVg0rllbd"
      },
      "source": [
        "### 특징벡터 추출\n",
        "#### PEMINER\n",
        "PEMINER는 전체 데이터 모두 특징벡터로 이용한다.   \n",
        "#### EMBER \n",
        "EMBER는 histogram 정보, string 정보, general 정보, section의 갯수,section entropy중 가장 큰 값, section size중 가장 큰 크기, datadirectory갯수, byteentropy 정규화 값, header optional값, export 갯수를 특징 벡터로 이용하였다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoDZVT_UlWdm"
      },
      "source": [
        "class PeminerParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def process_report(self):\n",
        "        '''\n",
        "            전체 데이터 사용        \n",
        "        '''\n",
        "        \n",
        "        self.vector = [value for _, value in sorted(self.report.items(), key=lambda x: x[0])]\n",
        "        return self.vector\n",
        "    \n",
        "\n",
        "class EmberParser:\n",
        "    '''\n",
        "        예제에서 사용하지 않은 특징도 사용하여 벡터화 할 것을 권장\n",
        "    '''\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def get_histogram_info(self):\n",
        "        histogram = np.array(self.report[\"histogram\"])\n",
        "        total = histogram.sum()\n",
        "        vector = histogram / total\n",
        "        return vector.tolist()\n",
        "    \n",
        "    def get_string_info(self):\n",
        "        strings = self.report[\"strings\"]\n",
        "\n",
        "        hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0\n",
        "        vector = [\n",
        "            strings['numstrings'], \n",
        "            strings['avlength'], \n",
        "            strings['printables'],\n",
        "            strings['entropy'], \n",
        "            strings['paths'], \n",
        "            strings['urls'],\n",
        "            strings['registry'], \n",
        "            strings['MZ']\n",
        "        ]\n",
        "        vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()\n",
        "        return vector\n",
        "    \n",
        "    def get_header_optional_info(self):\n",
        "      header = self.report[\"header\"]\n",
        "      optional = header['optional']\n",
        "      vector = [\n",
        "          optional['major_image_version'],\n",
        "          optional['minor_image_version'],\n",
        "          optional['major_linker_version'],\n",
        "          optional['minor_linker_version'],\n",
        "          optional['major_operating_system_version'],\n",
        "          optional['minor_operating_system_version'],\n",
        "          optional['major_subsystem_version'],\n",
        "          optional['minor_subsystem_version'],\n",
        "          optional['sizeof_code'],\n",
        "          optional['sizeof_headers'],\n",
        "          optional['sizeof_heap_commit']\n",
        "      ]\n",
        "      return vector\n",
        "    \n",
        "    def get_section_number(self):\n",
        "      section = self.report[\"section\"]\n",
        "      vector = [len(section)]\n",
        "      return vector\n",
        "\n",
        "    def get_section_entropy(self):\n",
        "      section = self.report[\"section\"]\n",
        "      section = section['sections']\n",
        "      if len(section) == 0 : \n",
        "        vector = [-11]\n",
        "        return vector\n",
        "      else : \n",
        "        entropy = 0\n",
        "        for sections in section:\n",
        "          if entropy < float(sections['entropy']):\n",
        "            entropy = float(sections['entropy'])\n",
        "        vector = [entropy]\n",
        "        return vector\n",
        "\n",
        "    def get_section_size(self):\n",
        "      section = self.report[\"section\"]\n",
        "      section = section['sections']\n",
        "      if len(section) == 0 : \n",
        "        vector = [-11]\n",
        "        return vector\n",
        "      else :\n",
        "        size = 0\n",
        "        for sections in section:\n",
        "          if size < float(sections['size']) :\n",
        "            size = float(sections['size'])\n",
        "        vector = [size]\n",
        "        return vector\n",
        "\n",
        "    def get_datadirectories_number(self):\n",
        "      data = self.report[\"datadirectories\"]\n",
        "      vector = [len(data)]\n",
        "      return vector\n",
        "\n",
        "    def get_general_file_info(self):\n",
        "        general = self.report[\"general\"]\n",
        "        vector = [\n",
        "            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],\n",
        "            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],\n",
        "            general['symbols']\n",
        "        ]\n",
        "        return vector\n",
        "    \n",
        "    def get_byteentropy(self):\n",
        "      byteentropy = np.array(self.report[\"byteentropy\"])\n",
        "      total = byteentropy.sum()\n",
        "      vector = byteentropy / total\n",
        "      return vector.tolist()\n",
        "      \n",
        "    def get_export_number(self):\n",
        "      export = self.report[\"exports\"]\n",
        "      vector = [len(export)]\n",
        "      return vector\n",
        "\n",
        "    def process_report(self):\n",
        "        vector = []\n",
        "        vector += self.get_general_file_info()\n",
        "        vector += self.get_histogram_info()\n",
        "        vector += self.get_string_info()\n",
        "        vector += self.get_byteentropy()\n",
        "        vector += self.get_header_optional_info()\n",
        "        vector += self.get_section_number()\n",
        "        vector += self.get_section_entropy()\n",
        "        vector += self.get_section_size()\n",
        "        vector += self.get_datadirectories_number()\n",
        "        vector += self.get_export_number()\n",
        "\n",
        "        '''\n",
        "            특징 추가\n",
        "            \n",
        "        '''\n",
        "        return vector\n",
        "    \n",
        "class PestudioParser:\n",
        "    '''\n",
        "        사용할 특징을 선택하여 벡터화 할 것을 권장\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def process_report(self):\n",
        "        pass"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdaXFQsplcfl"
      },
      "source": [
        "### 학습데이터 구성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1_xoMZtlZzo",
        "outputId": "f2580bdb-dd82-432a-87d1-99eb6f797c5c"
      },
      "source": [
        "# 데이터의 특징 벡터 모음(2차원 리스트) : X\n",
        "# 데이터의 레이블 모음(1차원 리스트) : y\n",
        "X, y = [], []\n",
        "\n",
        "for fname in file_list:\n",
        "    feature_vector = []\n",
        "    fname = fname.split(\"/\")[4]\n",
        "    fname = fname.split(\".\")[0]\n",
        "    label = label_table[fname]\n",
        "    for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/학습데이터/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "    X.append(feature_vector)\n",
        "    y.append(label)\n",
        "\n",
        "np.asarray(X).shape, np.asarray(y).shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 830), (20000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUglHmh3V3ss"
      },
      "source": [
        "### 검증데이터 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM41B9pL9YwI",
        "outputId": "2f4f8a28-e092-4e8c-d75e-bd3e342e9ab6"
      },
      "source": [
        "# 데이터의 특징 벡터 모음(2차원 리스트) : Xt\n",
        "# 데이터의 레이블 모음(1차원 리스트) : yt\n",
        "Xt, yt = [], []\n",
        "\n",
        "for fname in file_test_list:\n",
        "    feature_vector = []\n",
        "    fname = fname.split(\"/\")[4]\n",
        "    fname = fname.split(\".\")[0]\n",
        "    label = label_test_table[fname]\n",
        "    for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/검증데이터/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "    Xt.append(feature_vector)\n",
        "    yt.append(label)\n",
        "\n",
        "np.asarray(Xt).shape, np.asarray(yt).shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 830), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ_g208BltDZ"
      },
      "source": [
        "### 학습 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Sj6LGmluXs",
        "outputId": "91a87bf5-2ee0-46e7-c92c-10633ecaea5e"
      },
      "source": [
        "# 학습\n",
        "models = []\n",
        "for model in [\"lgb\",\"rf\",\"knn\"]:\n",
        "    clf = train(X, y, model)\n",
        "    models.append(clf)\n",
        "\n",
        "# 검증\n",
        "# 실제 검증 시에는 제공한 검증데이터를 검증에 사용해야 함\n",
        "for model in models:\n",
        "    evaluate(Xt, yt, model)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9525\n",
            "정확도 0.9434\n",
            "정확도 0.9042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHolonc-lweF"
      },
      "source": [
        "### 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CloPNYUflyU8"
      },
      "source": [
        "def ensemble_result(X, y, models):\n",
        "    '''\n",
        "        학습된 모델들의 결과를 앙상블하는 함수\n",
        "\t\n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param models: 1개 이상의 학습된 머신러닝 모델 객체를 가지는 1차원 리스트\n",
        "    '''\n",
        "    \n",
        "    # Soft Voting\n",
        "    # https://devkor.tistory.com/entry/Soft-Voting-%EA%B3%BC-Hard-Voting\n",
        "    predicts = []\n",
        "    for model in models:\n",
        "        prob = [result for _, result in model.predict_proba(X)]\n",
        "        predicts.append(prob)\n",
        "    \n",
        "    predict = np.mean(predicts, axis=0)\n",
        "    predict = [1 if x >= 0.5 else 0 for x in predict]\n",
        "        \n",
        "    print(\"정확도\", accuracy_score(y, predict))\n",
        "def ensemble_models(X, models) :\n",
        "    '''\n",
        "        학습된 모델들의 결과를 앙상블하는 함수\n",
        "\n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param models: 1개 이상의 학습된 머신러닝 모델 객체를 가지는 1차원 리스트\n",
        "    '''\n",
        "\n",
        "    predicts = []\n",
        "    for model in models :\n",
        "        prob = [result for _, result in model.predict_proba(X)]\n",
        "        predicts.append(prob)\n",
        "    \n",
        "    predict = np.mean(predicts, axis=0)\n",
        "    predict = [1 if x >= 0.5 else 0 for x in predict]\n",
        "\n",
        "    return predict"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX2OicGpl1qQ",
        "outputId": "04e7d313-42da-4b7c-fc72-52aaa0556b55"
      },
      "source": [
        "ensemble_result(Xt, yt, models)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teu7GS2VWG94"
      },
      "source": [
        "### 테스트 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj9wQdo3Ov03"
      },
      "source": [
        "test_list = glob.glob('/content/EMBER/테스트데이터/*.json')\n",
        "test_label = []\n",
        "\n",
        "test_result = []"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWHM1NftWJKd"
      },
      "source": [
        "### 테스트 데이터 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy5Y6mi7OxRA",
        "outputId": "bc06bb32-2fea-404c-a779-da5dba10ec3b"
      },
      "source": [
        "# 데이터의 특징 벡터 모음(2차원 리스트) : X_test\n",
        "# 데이터의 예측결과 모음(1차원 리스트) : y_test\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for fname in test_list:\n",
        "    feature_vector = []\n",
        "    fname = fname.split(\"/\")[4]\n",
        "    fname = fname.split(\".\")[0]\n",
        "    for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"{data}/테스트데이터/{fname}.json\"\n",
        "        if data == \"PEMINER\":\n",
        "            feature_vector += PeminerParser(path).process_report()\n",
        "        else:\n",
        "            feature_vector += EmberParser(path).process_report()\n",
        "    X_test.append(feature_vector)\n",
        "    test_label.append(fname)\n",
        "\n",
        "np.asarray(X_test).shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 830)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKfP-xUBWWHL"
      },
      "source": [
        "### 테스트 데이터 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZHiMdwNOy9x"
      },
      "source": [
        "y_test = ensemble_models(X_test, models)\n",
        "\n",
        "for i in range(10000) :\n",
        "    test_result.append([test_label[i], y_test[i]])\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toDkpq-2WY-X"
      },
      "source": [
        "### 테스트 예측 데이터 .csv 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vzjBL7hO0ae"
      },
      "source": [
        "write_path = '/content/drive/MyDrive/predict.csv'\n",
        "\n",
        "write_label_csv(write_path, test_result)"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}
